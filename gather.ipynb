{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Webscraping!\n",
    "\n",
    "I use multithreading to speed up scraping and store results in a queue for thread safety."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T16:21:22.198959Z",
     "iopub.status.busy": "2025-08-02T16:21:22.198959Z",
     "iopub.status.idle": "2025-08-02T16:21:24.688207Z",
     "shell.execute_reply": "2025-08-02T16:21:24.688207Z"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import time\n",
    "import logging\n",
    "from queue import Queue\n",
    "# Athlete ID range (I checked manually)\n",
    "start_id = 1\n",
    "end_id = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Athlete Information (birthday, country, height, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T16:21:24.688207Z",
     "iopub.status.busy": "2025-08-02T16:21:24.688207Z",
     "iopub.status.idle": "2025-08-02T16:21:24.697548Z",
     "shell.execute_reply": "2025-08-02T16:21:24.697548Z"
    }
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(filename='athlete_data_errors.log', level=logging.ERROR, format='%(asctime)s %(levelname)s: %(message)s')\n",
    "\n",
    "def fetch_athlete_data(athlete_id, data_queue, failed_queue):\n",
    "    headers = {\n",
    "        'X-Csrf-Token': 'QsiFWuxEY1S9h_-dQgRA_7S5w9uvvmXsjq56QbTPw4i_g_XR68rMCBFFhW6HngBRtHskfN5yjX8GQmawqs8BlQ',\n",
    "        'Referer': 'https://ifsc.results.info',\n",
    "        'Cookie': 'session_id=_verticallife_resultservice_session=6RHN3xZrXnftTiScNfSHg7BVvuebLzGAmC9P5vIpzdySn2vG7VwQpjSZRDHug%2BPKCWlkt831HjLvHsPoVKrzTGsPVR6mqSOtjHB%2Bwht%2Bj39KxYO%2FJlaU6zmh8VhNFEl9bXHiOlPGk8AxnZqiBSYKTxJFCqh34nqdurXfFDcsRnbEtYCixcOdx%2F32E4zYGLVw7DSXXIKOVTUivS43UJZq5zDWPctX95UWm%2FD7%2B6UYT2s0B%2B3XJVPgjMWCMR%2FVZs%2FQC45Gjm4uCpHHe8Yt73nM3J%2Br43V1HuHGSvRpRczrJ4QdovlJHDEpg4rjUA%3D%3D',\n",
    "    }\n",
    "    url = f\"https://ifsc.results.info/api/v1/athletes/{athlete_id}\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, headers=headers, timeout=120)\n",
    "        if response.status_code == 200:\n",
    "            athlete_data = response.json()\n",
    "            # Ensure we handle missing fields safely using .get()\n",
    "            data_queue.put({\n",
    "                'athlete_id': athlete_data.get('id', None),\n",
    "                'firstname': athlete_data.get('firstname', None),\n",
    "                'lastname': athlete_data.get('lastname', None),\n",
    "                'age': athlete_data.get('age', None),\n",
    "                'gender': athlete_data.get('gender', None),\n",
    "                'country': athlete_data.get('country', None),\n",
    "                'height': athlete_data.get('height', None),\n",
    "                'arm_span': athlete_data.get('arm_span', None),\n",
    "                'paraclimbing_sport_class': athlete_data.get('paraclimbing_sport_class', None),\n",
    "                'birthday': athlete_data.get('birthday', None),\n",
    "            })\n",
    "        else:\n",
    "            logging.error(f\"Failed to fetch athlete ID {athlete_id}: Status {response.status_code}, Reason: {response.reason}\")\n",
    "            failed_queue.put(athlete_id)\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error fetching data for athlete ID {athlete_id}: {e}\")\n",
    "        failed_queue.put(athlete_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T16:21:24.697548Z",
     "iopub.status.busy": "2025-08-02T16:21:24.697548Z",
     "iopub.status.idle": "2025-08-02T16:21:24.705309Z",
     "shell.execute_reply": "2025-08-02T16:21:24.705309Z"
    }
   },
   "outputs": [],
   "source": [
    "def retry_failed_athlete_info(failed_ids, max_retries=2, delay=2):\n",
    "    retry_results = []\n",
    "    failed_queue = Queue()\n",
    "\n",
    "    for retry_count in range(max_retries):\n",
    "        print(f\"Retry attempt {retry_count + 1} for {len(failed_ids)} failed athlete IDs\")\n",
    "        retry_futures = []\n",
    "        data_queue = Queue()\n",
    "        \n",
    "        with ThreadPoolExecutor(max_workers=20) as executor:\n",
    "            retry_futures = {executor.submit(fetch_athlete_data, athlete_id, data_queue, failed_queue): athlete_id for athlete_id in failed_ids}\n",
    "            failed_ids = []  # Reset failed_ids list for next retry\n",
    "        \n",
    "            for future in as_completed(retry_futures):\n",
    "                try:\n",
    "                    future.result()\n",
    "                except Exception as e:\n",
    "                    logging.error(f\"Error during retry for athlete: {e}\")\n",
    "        \n",
    "        # Collect results from queues\n",
    "        while not data_queue.empty():\n",
    "            retry_results.append(data_queue.get())\n",
    "        \n",
    "        while not failed_queue.empty():\n",
    "            failed_ids.append(failed_queue.get())\n",
    "        \n",
    "        if not failed_ids:\n",
    "            break  # Exit loop if no more failed IDs\n",
    "        \n",
    "        time.sleep(delay)  # Wait between retries to avoid overloading the server\n",
    "    \n",
    "    if failed_ids:\n",
    "        print(f\"Final failed athlete IDs after {max_retries} retries: {failed_ids}\")\n",
    "    \n",
    "    return retry_results, failed_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T16:21:24.705309Z",
     "iopub.status.busy": "2025-08-02T16:21:24.705309Z",
     "iopub.status.idle": "2025-08-02T16:21:24.712585Z",
     "shell.execute_reply": "2025-08-02T16:21:24.712585Z"
    }
   },
   "outputs": [],
   "source": [
    "def scrape_athletes_parallel(start_id, end_id, max_workers=25):\n",
    "    athletes_info = []\n",
    "    failed_ids = []\n",
    "    data_queue = Queue()\n",
    "    failed_queue = Queue()\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        # Submit tasks for each athlete ID\n",
    "        futures = {executor.submit(fetch_athlete_data, athlete_id, data_queue, failed_queue): athlete_id for athlete_id in range(start_id, end_id + 1)}\n",
    "        \n",
    "        for future in as_completed(futures):\n",
    "            try:\n",
    "                future.result()\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error during scraping: {e}\")\n",
    "    \n",
    "    # Collect results from queues\n",
    "    while not data_queue.empty():\n",
    "        athletes_info.append(data_queue.get())\n",
    "    \n",
    "    while not failed_queue.empty():\n",
    "        failed_ids.append(failed_queue.get())\n",
    "    \n",
    "    # Retry for failed athlete IDs\n",
    "    if failed_ids:\n",
    "        retry_results, failed_ids = retry_failed_athlete_info(failed_ids)\n",
    "        athletes_info.extend(retry_results)  # Add successful retries\n",
    "\n",
    "    return athletes_info, failed_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T16:21:24.714094Z",
     "iopub.status.busy": "2025-08-02T16:21:24.714094Z",
     "iopub.status.idle": "2025-08-02T16:21:25.598158Z",
     "shell.execute_reply": "2025-08-02T16:21:25.598158Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped 10 athletes\n"
     ]
    }
   ],
   "source": [
    "# Scrape athlete data from the range and create a DataFrame\n",
    "athletes_info_list, failed_ids = scrape_athletes_parallel(start_id, end_id)\n",
    "athletes_info_df = pd.DataFrame(athletes_info_list)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "athletes_info_df.to_csv('athlete_information.csv', index=False)\n",
    "\n",
    "print(f\"Scraped {len(athletes_info_df)} athletes\")\n",
    "if failed_ids:\n",
    "    print(f\"Failed to fetch data for {len(failed_ids)} athlete IDs after retries: {failed_ids}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Athlete Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T16:21:25.643968Z",
     "iopub.status.busy": "2025-08-02T16:21:25.643968Z",
     "iopub.status.idle": "2025-08-02T16:21:25.650483Z",
     "shell.execute_reply": "2025-08-02T16:21:25.650483Z"
    }
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(filename='scraping_errors.log', level=logging.ERROR, format='%(asctime)s %(levelname)s: %(message)s')\n",
    "\n",
    "def fetch_athlete_results(athlete_id, results_queue, failed_queue):\n",
    "    headers = {\n",
    "        'X-Csrf-Token': 'QsiFWuxEY1S9h_-dQgRA_7S5w9uvvmXsjq56QbTPw4i_g_XR68rMCBFFhW6HngBRtHskfN5yjX8GQmawqs8BlQ',\n",
    "        'Referer': 'https://ifsc.results.info',\n",
    "        'Cookie': 'session_id=_verticallife_resultservice_session=6RHN3xZrXnftTiScNfSHg7BVvuebLzGAmC9P5vIpzdySn2vG7VwQpjSZRDHug%2BPKCWlkt831HjLvHsPoVKrzTGsPVR6mqSOtjHB%2Bwht%2Bj39KxYO%2FJlaU6zmh8VhNFEl9bXHiOlPGk8AxnZqiBSYKTxJFCqh34nqdurXfFDcsRnbEtYCixcOdx%2F32E4zYGLVw7DSXXIKOVTUivS43UJZq5zDWPctX95UWm%2FD7%2B6UYT2s0B%2B3XJVPgjMWCMR%2FVZs%2FQC45Gjm4uCpHHe8Yt73nM3J%2Br43V1HuHGSvRpRczrJ4QdovlJHDEpg4rjUA%3D%3D',\n",
    "    }\n",
    "    url = f\"https://ifsc.results.info/api/v1/athletes/{athlete_id}\"\n",
    "    \n",
    "    try:\n",
    "        response = requests.get(url, headers=headers)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            athlete_data = response.json()\n",
    "            results = []\n",
    "            \n",
    "            for result in athlete_data.get('all_results', []):\n",
    "                # Use `.get()` with default values to avoid KeyErrors if fields are missing\n",
    "                results.append({\n",
    "                    'athlete_id': athlete_id,\n",
    "                    'rank': result.get('rank', None),  # Use None if 'rank' is missing\n",
    "                    'discipline': result.get('discipline', None),\n",
    "                    'season': result.get('season', None),\n",
    "                    'date': result.get('date', None),\n",
    "                    'event_id': result.get('event_id', None),\n",
    "                    'event_location': result.get('event_location', None),\n",
    "                    'd_cat': result.get('d_cat', None),\n",
    "                })\n",
    "            results_queue.put(results)\n",
    "        else:\n",
    "            logging.error(f\"Failed to fetch athlete ID {athlete_id}: Status {response.status_code}, Reason: {response.reason}\")\n",
    "            failed_queue.put(athlete_id)\n",
    "    \n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error fetching results for athlete ID {athlete_id}: {e}\")\n",
    "        failed_queue.put(athlete_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T16:21:25.651492Z",
     "iopub.status.busy": "2025-08-02T16:21:25.651492Z",
     "iopub.status.idle": "2025-08-02T16:21:25.658037Z",
     "shell.execute_reply": "2025-08-02T16:21:25.658037Z"
    }
   },
   "outputs": [],
   "source": [
    "def retry_failed_athletes(failed_ids, max_retries=3, delay=2):\n",
    "    retry_results = []\n",
    "    failed_queue = Queue()\n",
    "\n",
    "    for retry_count in range(max_retries):\n",
    "        print(f\"Retry attempt {retry_count + 1} for {len(failed_ids)} failed athlete IDs\")\n",
    "        retry_futures = []\n",
    "        results_queue = Queue()\n",
    "        \n",
    "        with ThreadPoolExecutor(max_workers=20) as executor:\n",
    "            retry_futures = {executor.submit(fetch_athlete_results, athlete_id, results_queue, failed_queue): athlete_id for athlete_id in failed_ids}\n",
    "            failed_ids = []  # Reset failed_ids list for next retry\n",
    "        \n",
    "            for future in as_completed(retry_futures):\n",
    "                try:\n",
    "                    future.result()\n",
    "                except Exception as e:\n",
    "                    logging.error(f\"Error during retry for athlete: {e}\")\n",
    "        \n",
    "        # Collect results from queues\n",
    "        while not results_queue.empty():\n",
    "            retry_results.extend(results_queue.get())\n",
    "        \n",
    "        while not failed_queue.empty():\n",
    "            failed_ids.append(failed_queue.get())\n",
    "        \n",
    "        if not failed_ids:\n",
    "            break  # Exit loop if no more failed IDs\n",
    "        \n",
    "        time.sleep(delay)  # Wait between retries to avoid overloading the server\n",
    "    \n",
    "    if failed_ids:\n",
    "        print(f\"Final failed athlete IDs after {max_retries} retries: {failed_ids}\")\n",
    "    \n",
    "    return retry_results, failed_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T16:21:25.658548Z",
     "iopub.status.busy": "2025-08-02T16:21:25.658548Z",
     "iopub.status.idle": "2025-08-02T16:21:25.664526Z",
     "shell.execute_reply": "2025-08-02T16:21:25.664526Z"
    }
   },
   "outputs": [],
   "source": [
    "def scrape_athlete_results_parallel(start_id, end_id, max_workers=60):\n",
    "    athlete_results = []\n",
    "    failed_ids = []\n",
    "    results_queue = Queue()\n",
    "    failed_queue = Queue()\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = {executor.submit(fetch_athlete_results, athlete_id, results_queue, failed_queue): athlete_id for athlete_id in range(start_id, end_id + 1)}\n",
    "        \n",
    "        for future in as_completed(futures):\n",
    "            try:\n",
    "                future.result()\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error during scraping: {e}\")\n",
    "    \n",
    "    # Collect results from queues\n",
    "    while not results_queue.empty():\n",
    "        athlete_results.extend(results_queue.get())\n",
    "    \n",
    "    while not failed_queue.empty():\n",
    "        failed_ids.append(failed_queue.get())\n",
    "    \n",
    "    # Retry for failed athlete IDs\n",
    "    if failed_ids:\n",
    "        retry_results, failed_ids = retry_failed_athletes(failed_ids)\n",
    "        athlete_results.extend(retry_results)  # Add successful retries\n",
    "    \n",
    "    return athlete_results, failed_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-08-02T16:21:25.664526Z",
     "iopub.status.busy": "2025-08-02T16:21:25.664526Z",
     "iopub.status.idle": "2025-08-02T16:21:26.284747Z",
     "shell.execute_reply": "2025-08-02T16:21:26.284747Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraped results for 46 athlete events\n"
     ]
    }
   ],
   "source": [
    "athlete_results_list, failed_ids = scrape_athlete_results_parallel(start_id, end_id)\n",
    "athlete_results_df = pd.DataFrame(athlete_results_list)\n",
    "\n",
    "athlete_results_df.to_csv('athlete_results.csv', index=False)\n",
    "\n",
    "print(f\"Scraped results for {len(athlete_results_df)} athlete events\")\n",
    "if failed_ids:\n",
    "    print(f\"Failed to fetch data for {len(failed_ids)} athlete IDs after retries: {failed_ids}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
